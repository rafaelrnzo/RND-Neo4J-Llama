{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c6ca0e81a426a848c8b5a1050577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: fastapi 0.110.0 does not provide the extra 'standard'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for vllm (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1467 lines of output]\n",
      "  C:\\Users\\FIT\\AppData\\Local\\Temp\\pip-build-env-ml33aw7t\\overlay\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "  vLLM only supports Linux platform (including WSL) and MacOS.Building on win32, so vLLM may not be able to run correctly\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib\\vllm\n",
      "  copying vllm\\beam_search.py -> build\\lib\\vllm\n",
      "  copying vllm\\config.py -> build\\lib\\vllm\n",
      "  copying vllm\\connections.py -> build\\lib\\vllm\n",
      "  copying vllm\\envs.py -> build\\lib\\vllm\n",
      "  copying vllm\\forward_context.py -> build\\lib\\vllm\n",
      "  copying vllm\\logger.py -> build\\lib\\vllm\n",
      "  copying vllm\\logits_process.py -> build\\lib\\vllm\n",
      "  copying vllm\\outputs.py -> build\\lib\\vllm\n",
      "  copying vllm\\pooling_params.py -> build\\lib\\vllm\n",
      "  copying vllm\\sampling_params.py -> build\\lib\\vllm\n",
      "  copying vllm\\scalar_type.py -> build\\lib\\vllm\n",
      "  copying vllm\\scripts.py -> build\\lib\\vllm\n",
      "  copying vllm\\sequence.py -> build\\lib\\vllm\n",
      "  copying vllm\\tracing.py -> build\\lib\\vllm\n",
      "  copying vllm\\utils.py -> build\\lib\\vllm\n",
      "  copying vllm\\version.py -> build\\lib\\vllm\n",
      "  copying vllm\\_custom_ops.py -> build\\lib\\vllm\n",
      "  copying vllm\\_ipex_ops.py -> build\\lib\\vllm\n",
      "  copying vllm\\_version.py -> build\\lib\\vllm\n",
      "  copying vllm\\__init__.py -> build\\lib\\vllm\n",
      "  creating build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\layers.py -> build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\models.py -> build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\request.py -> build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\utils.py -> build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\worker_manager.py -> build\\lib\\vllm\\adapter_commons\n",
      "  copying vllm\\adapter_commons\\__init__.py -> build\\lib\\vllm\\adapter_commons\n",
      "  creating build\\lib\\vllm\\assets\n",
      "  copying vllm\\assets\\audio.py -> build\\lib\\vllm\\assets\n",
      "  copying vllm\\assets\\base.py -> build\\lib\\vllm\\assets\n",
      "  copying vllm\\assets\\image.py -> build\\lib\\vllm\\assets\n",
      "  copying vllm\\assets\\video.py -> build\\lib\\vllm\\assets\n",
      "  copying vllm\\assets\\__init__.py -> build\\lib\\vllm\\assets\n",
      "  creating build\\lib\\vllm\\attention\n",
      "  copying vllm\\attention\\layer.py -> build\\lib\\vllm\\attention\n",
      "  copying vllm\\attention\\selector.py -> build\\lib\\vllm\\attention\n",
      "  copying vllm\\attention\\__init__.py -> build\\lib\\vllm\\attention\n",
      "  creating build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\backends.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\compiler_interface.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\counter.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\decorators.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\fix_functionalization.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\fusion.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\fx_utils.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\inductor_pass.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\monitor.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\multi_output_match.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\pass_manager.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\reshapes.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\vllm_inductor_pass.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\wrapper.py -> build\\lib\\vllm\\compilation\n",
      "  copying vllm\\compilation\\__init__.py -> build\\lib\\vllm\\compilation\n",
      "  creating build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\block_manager.py -> build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\evictor.py -> build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\interfaces.py -> build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\placeholder_block_space_manager.py -> build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\scheduler.py -> build\\lib\\vllm\\core\n",
      "  copying vllm\\core\\__init__.py -> build\\lib\\vllm\\core\n",
      "  creating build\\lib\\vllm\\device_allocator\n",
      "  copying vllm\\device_allocator\\cumem.py -> build\\lib\\vllm\\device_allocator\n",
      "  copying vllm\\device_allocator\\__init__.py -> build\\lib\\vllm\\device_allocator\n",
      "  creating build\\lib\\vllm\\distributed\n",
      "  copying vllm\\distributed\\communication_op.py -> build\\lib\\vllm\\distributed\n",
      "  copying vllm\\distributed\\parallel_state.py -> build\\lib\\vllm\\distributed\n",
      "  copying vllm\\distributed\\utils.py -> build\\lib\\vllm\\distributed\n",
      "  copying vllm\\distributed\\__init__.py -> build\\lib\\vllm\\distributed\n",
      "  creating build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\arg_utils.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\async_llm_engine.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\async_timeout.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\llm_engine.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\metrics.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\metrics_types.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\protocol.py -> build\\lib\\vllm\\engine\n",
      "  copying vllm\\engine\\__init__.py -> build\\lib\\vllm\\engine\n",
      "  creating build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\api_server.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\chat_utils.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\launcher.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\llm.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\logger.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\utils.py -> build\\lib\\vllm\\entrypoints\n",
      "  copying vllm\\entrypoints\\__init__.py -> build\\lib\\vllm\\entrypoints\n",
      "  creating build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\executor_base.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\mp_distributed_executor.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\msgspec_utils.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\multiproc_worker_utils.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\ray_distributed_executor.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\ray_utils.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\uniproc_executor.py -> build\\lib\\vllm\\executor\n",
      "  copying vllm\\executor\\__init__.py -> build\\lib\\vllm\\executor\n",
      "  creating build\\lib\\vllm\\inputs\n",
      "  copying vllm\\inputs\\data.py -> build\\lib\\vllm\\inputs\n",
      "  copying vllm\\inputs\\parse.py -> build\\lib\\vllm\\inputs\n",
      "  copying vllm\\inputs\\preprocess.py -> build\\lib\\vllm\\inputs\n",
      "  copying vllm\\inputs\\registry.py -> build\\lib\\vllm\\inputs\n",
      "  copying vllm\\inputs\\__init__.py -> build\\lib\\vllm\\inputs\n",
      "  creating build\\lib\\vllm\\logging_utils\n",
      "  copying vllm\\logging_utils\\formatter.py -> build\\lib\\vllm\\logging_utils\n",
      "  copying vllm\\logging_utils\\__init__.py -> build\\lib\\vllm\\logging_utils\n",
      "  creating build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\fully_sharded_layers.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\layers.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\lora.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\models.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\peft_helper.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\request.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\utils.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\worker_manager.py -> build\\lib\\vllm\\lora\n",
      "  copying vllm\\lora\\__init__.py -> build\\lib\\vllm\\lora\n",
      "  creating build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\custom_op.py -> build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\parameter.py -> build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\pooling_metadata.py -> build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\sampling_metadata.py -> build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\utils.py -> build\\lib\\vllm\\model_executor\n",
      "  copying vllm\\model_executor\\__init__.py -> build\\lib\\vllm\\model_executor\n",
      "  creating build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\audio.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\base.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\hasher.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\image.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\inputs.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\parse.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\processing.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\profiling.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\registry.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\utils.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\video.py -> build\\lib\\vllm\\multimodal\n",
      "  copying vllm\\multimodal\\__init__.py -> build\\lib\\vllm\\multimodal\n",
      "  creating build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\cpu.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\cuda.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\hpu.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\interface.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\neuron.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\openvino.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\rocm.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\tpu.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\xpu.py -> build\\lib\\vllm\\platforms\n",
      "  copying vllm\\platforms\\__init__.py -> build\\lib\\vllm\\platforms\n",
      "  creating build\\lib\\vllm\\plugins\n",
      "  copying vllm\\plugins\\__init__.py -> build\\lib\\vllm\\plugins\n",
      "  creating build\\lib\\vllm\\profiler\n",
      "  copying vllm\\profiler\\layerwise_profile.py -> build\\lib\\vllm\\profiler\n",
      "  copying vllm\\profiler\\utils.py -> build\\lib\\vllm\\profiler\n",
      "  copying vllm\\profiler\\__init__.py -> build\\lib\\vllm\\profiler\n",
      "  creating build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\layers.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\models.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\request.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\utils.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\worker_manager.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  copying vllm\\prompt_adapter\\__init__.py -> build\\lib\\vllm\\prompt_adapter\n",
      "  creating build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\batch_expansion.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\draft_model_runner.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\interfaces.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\medusa_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\metrics.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\mlp_speculator_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\mqa_scorer.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\multi_step_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\ngram_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\proposer_worker_base.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\smaller_tp_proposer_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\spec_decode_worker.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\target_model_runner.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\top1_proposer.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\util.py -> build\\lib\\vllm\\spec_decode\n",
      "  copying vllm\\spec_decode\\__init__.py -> build\\lib\\vllm\\spec_decode\n",
      "  creating build\\lib\\vllm\\third_party\n",
      "  copying vllm\\third_party\\pynvml.py -> build\\lib\\vllm\\third_party\n",
      "  copying vllm\\third_party\\__init__.py -> build\\lib\\vllm\\third_party\n",
      "  creating build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\config.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\detokenizer.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\detokenizer_utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\processor.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\s3_utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\tokenizer.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\tokenizer_base.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\utils.py -> build\\lib\\vllm\\transformers_utils\n",
      "  copying vllm\\transformers_utils\\__init__.py -> build\\lib\\vllm\\transformers_utils\n",
      "  creating build\\lib\\vllm\\triton_utils\n",
      "  copying vllm\\triton_utils\\custom_cache_manager.py -> build\\lib\\vllm\\triton_utils\n",
      "  copying vllm\\triton_utils\\importing.py -> build\\lib\\vllm\\triton_utils\n",
      "  copying vllm\\triton_utils\\__init__.py -> build\\lib\\vllm\\triton_utils\n",
      "  creating build\\lib\\vllm\\usage\n",
      "  copying vllm\\usage\\usage_lib.py -> build\\lib\\vllm\\usage\n",
      "  copying vllm\\usage\\__init__.py -> build\\lib\\vllm\\usage\n",
      "  creating build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\kv_cache_interface.py -> build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\outputs.py -> build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\request.py -> build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\serial_utils.py -> build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\utils.py -> build\\lib\\vllm\\v1\n",
      "  copying vllm\\v1\\__init__.py -> build\\lib\\vllm\\v1\n",
      "  creating build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\cache_engine.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\cpu_enc_dec_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\cpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\cpu_pooling_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\cpu_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\enc_dec_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\hpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\hpu_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\model_runner_base.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\multi_step_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\multi_step_tpu_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\multi_step_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\neuron_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\neuron_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\openvino_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\openvino_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\pooling_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\tpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\tpu_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\utils.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\worker_base.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\xpu_model_runner.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\xpu_worker.py -> build\\lib\\vllm\\worker\n",
      "  copying vllm\\worker\\__init__.py -> build\\lib\\vllm\\worker\n",
      "  creating build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\abstract.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\blocksparse_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\flashinfer.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\flash_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\hpu_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\ipex_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\openvino.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\pallas.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\placeholder_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\rocm_flash_attn.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\torch_sdpa.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\triton_mla.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\utils.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\xformers.py -> build\\lib\\vllm\\attention\\backends\n",
      "  copying vllm\\attention\\backends\\__init__.py -> build\\lib\\vllm\\attention\\backends\n",
      "  creating build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\hpu_paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\ipex_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\nki_flash_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\paged_attn.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\prefix_prefill.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\triton_decode_attention.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\triton_flash_attention.py -> build\\lib\\vllm\\attention\\ops\n",
      "  copying vllm\\attention\\ops\\__init__.py -> build\\lib\\vllm\\attention\\ops\n",
      "  creating build\\lib\\vllm\\attention\\backends\\mla\n",
      "  copying vllm\\attention\\backends\\mla\\utils.py -> build\\lib\\vllm\\attention\\backends\\mla\n",
      "  copying vllm\\attention\\backends\\mla\\__init__.py -> build\\lib\\vllm\\attention\\backends\\mla\n",
      "  creating build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying vllm\\attention\\ops\\blocksparse_attention\\blocksparse_attention_kernel.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying vllm\\attention\\ops\\blocksparse_attention\\interface.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying vllm\\attention\\ops\\blocksparse_attention\\utils.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying vllm\\attention\\ops\\blocksparse_attention\\__init__.py -> build\\lib\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  creating build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\block_table.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\common.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\cpu_gpu_block_allocator.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\interfaces.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\naive_block.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\prefix_caching_block.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\utils.py -> build\\lib\\vllm\\core\\block\n",
      "  copying vllm\\core\\block\\__init__.py -> build\\lib\\vllm\\core\\block\n",
      "  creating build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\custom_all_reduce_utils.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\hpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\pynccl.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  copying vllm\\distributed\\device_communicators\\__init__.py -> build\\lib\\vllm\\distributed\\device_communicators\n",
      "  creating build\\lib\\vllm\\distributed\\kv_transfer\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_transfer_agent.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "  copying vllm\\distributed\\kv_transfer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "  creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_connector\\simple_connector.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  creating build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  creating build\\lib\\vllm\\engine\\multiprocessing\n",
      "  copying vllm\\engine\\multiprocessing\\client.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "  copying vllm\\engine\\multiprocessing\\engine.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "  copying vllm\\engine\\multiprocessing\\__init__.py -> build\\lib\\vllm\\engine\\multiprocessing\n",
      "  creating build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\interfaces.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\multi_step.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\single_step.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\stop_checker.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\util.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  copying vllm\\engine\\output_processor\\__init__.py -> build\\lib\\vllm\\engine\\output_processor\n",
      "  creating build\\lib\\vllm\\entrypoints\\cli\n",
      "  copying vllm\\entrypoints\\cli\\main.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "  copying vllm\\entrypoints\\cli\\openai.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "  copying vllm\\entrypoints\\cli\\serve.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "  copying vllm\\entrypoints\\cli\\types.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "  copying vllm\\entrypoints\\cli\\__init__.py -> build\\lib\\vllm\\entrypoints\\cli\n",
      "  creating build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\api_server.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\cli_args.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\logits_processors.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\protocol.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\run_batch.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_chat.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_completion.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_embedding.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_engine.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_models.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_pooling.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_rerank.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_score.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\serving_transcription.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  copying vllm\\entrypoints\\openai\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\n",
      "  creating build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying vllm\\entrypoints\\openai\\reasoning_parsers\\abs_reasoning_parsers.py -> build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying vllm\\entrypoints\\openai\\reasoning_parsers\\deepseek_r1_reasoning_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying vllm\\entrypoints\\openai\\reasoning_parsers\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  creating build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  creating build\\lib\\vllm\\lora\\ops\n",
      "  copying vllm\\lora\\ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\n",
      "  creating build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\punica_base.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\punica_hpu.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\utils.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  copying vllm\\lora\\punica_wrapper\\__init__.py -> build\\lib\\vllm\\lora\\punica_wrapper\n",
      "  creating build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "  copying vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "  copying vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\torch_ops\n",
      "  creating build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\bgmv_expand.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\bgmv_expand_slice.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\bgmv_shrink.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\sgmv_expand.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\sgmv_shrink.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\utils.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  copying vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\lib\\vllm\\lora\\ops\\triton_ops\n",
      "  creating build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\guided_fields.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\lm_format_enforcer_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\outlines_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\outlines_logits_processors.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\utils.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\xgrammar_decoding.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  copying vllm\\model_executor\\guided_decoding\\__init__.py -> build\\lib\\vllm\\model_executor\\guided_decoding\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\activation.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\layernorm.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\linear.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\logits_processor.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\pooler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\rejection_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\resampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\rotary_embedding.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\spec_decode_base_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\typical_acceptance_sampler.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\utils.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\vocab_parallel_embedding.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  copying vllm\\model_executor\\layers\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\n",
      "  creating build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\adapters.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\arctic.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\aria.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\baichuan.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\bamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\bart.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\bert.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\blip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\blip2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\bloom.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\chameleon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\chatglm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\clip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\commandr.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\dbrx.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\decilm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\deepseek.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\deepseek_mtp.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\deepseek_v2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\deepseek_vl2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\eagle.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\exaone.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\fairseq2_llama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\falcon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\florence2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\fuyu.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gemma.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gemma2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\glm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\glm4v.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gpt2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gpt_bigcode.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gpt_j.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gpt_neox.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\granite.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\granitemoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\gritlm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\h2ovl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\idefics2_vision_model.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\idefics3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\interfaces.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\interfaces_base.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\internlm2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\internlm2_ve.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\internvl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\intern_vit.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\jais.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\jamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\llama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\llava.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\llava_next.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\llava_next_video.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\llava_onevision.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mamba.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mamba2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mamba_cache.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\medusa.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\minicpm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\minicpm3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\minicpmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\minicpmv.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mixtral_quant.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mllama.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mlp_speculator.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\module_mapping.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\molmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\mpt.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\nemotron.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\nvlm_d.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\olmo.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\olmo2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\olmoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\opt.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\orion.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\paligemma.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\persimmon.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\phi.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\phi3.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\phi3v.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\phi3_small.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\phimoe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\pixtral.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\prithvi_geospatial_mae.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2_5_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2_audio.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2_moe.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2_rm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen2_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\qwen_vl.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\registry.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\roberta.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\siglip.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\solar.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\stablelm.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\starcoder2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\telechat2.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\transformers.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\ultravox.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\utils.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\vision.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\whisper.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  copying vllm\\model_executor\\models\\__init__.py -> build\\lib\\vllm\\model_executor\\models\n",
      "  creating build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\loader.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\neuron.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\openvino.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\tensorizer.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\weight_utils.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  copying vllm\\model_executor\\model_loader\\__init__.py -> build\\lib\\vllm\\model_executor\\model_loader\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\fused_marlin_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\fused_moe.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\layer.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\moe_pallas.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\moe_torch_iterative.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "  copying vllm\\model_executor\\layers\\mamba\\mamba_mixer.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "  copying vllm\\model_executor\\layers\\mamba\\mamba_mixer2.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "  copying vllm\\model_executor\\layers\\mamba\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\aqlm.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\awq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\awq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\awq_triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\base_config.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\bitsandbytes.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\deepspeedfp.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\experts_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\fbgemm_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\gguf.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\gptq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\gptq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\gptq_marlin_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\hqq_marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\ipex_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kv_cache.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\modelopt.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\moe_wna16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\neuron_quant.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\ptpc_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\qqq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\schema.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\tpu_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  copying vllm\\model_executor\\layers\\quantization\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\causal_conv1d.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\mamba_ssm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_bmm.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_scan.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_state.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_combined.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\ssd_state_passing.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying vllm\\model_executor\\layers\\mamba\\ops\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\triton_scaled_mm.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\quark.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\quark_moe.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\fp8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\gptq_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\layer_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\machete_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\marlin_utils_test_qqq.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\quant_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\w8a8_utils.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_24.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a16_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_wNa16.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\exllama.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\machete.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\marlin.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\MPLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cutlass.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\ScaledMMLinearKernel.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\triton.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\xla.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_scheme.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_fp8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_int8.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying vllm\\model_executor\\layers\\quantization\\quark\\schemes\\__init__.py -> build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  creating build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\arctic.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\chatglm.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\cohere2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\dbrx.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\eagle.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\exaone.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\falcon.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\h2ovl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\internvl.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\jais.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\medusa.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\mllama.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\mlp_speculator.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\mpt.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\nemotron.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\nvlm_d.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\olmo2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\solar.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\telechat2.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\ultravox.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  copying vllm\\transformers_utils\\configs\\__init__.py -> build\\lib\\vllm\\transformers_utils\\configs\n",
      "  creating build\\lib\\vllm\\transformers_utils\\processors\n",
      "  copying vllm\\transformers_utils\\processors\\deepseek_vl2.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
      "  copying vllm\\transformers_utils\\processors\\__init__.py -> build\\lib\\vllm\\transformers_utils\\processors\n",
      "  creating build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "  copying vllm\\transformers_utils\\tokenizers\\mistral.py -> build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "  copying vllm\\transformers_utils\\tokenizers\\__init__.py -> build\\lib\\vllm\\transformers_utils\\tokenizers\n",
      "  creating build\\lib\\vllm\\transformers_utils\\tokenizer_group\n",
      "  copying vllm\\transformers_utils\\tokenizer_group\\base_tokenizer_group.py -> build\\lib\\vllm\\transformers_utils\\tokenizer_group\n",
      "  copying vllm\\transformers_utils\\tokenizer_group\\ray_tokenizer_group.py -> build\\lib\\vllm\\transformers_utils\\tokenizer_group\n",
      "  copying vllm\\transformers_utils\\tokenizer_group\\tokenizer_group.py -> build\\lib\\vllm\\transformers_utils\\tokenizer_group\n",
      "  copying vllm\\transformers_utils\\tokenizer_group\\__init__.py -> build\\lib\\vllm\\transformers_utils\\tokenizer_group\n",
      "  creating build\\lib\\vllm\\v1\\attention\n",
      "  copying vllm\\v1\\attention\\__init__.py -> build\\lib\\vllm\\v1\\attention\n",
      "  creating build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\encoder_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\kv_cache_manager.py -> build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\kv_cache_utils.py -> build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\scheduler.py -> build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\scheduler_output.py -> build\\lib\\vllm\\v1\\core\n",
      "  copying vllm\\v1\\core\\__init__.py -> build\\lib\\vllm\\v1\\core\n",
      "  creating build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\async_llm.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\core.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\core_client.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\detokenizer.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\llm_engine.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\logprobs.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\mm_input_cache.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\output_processor.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\processor.py -> build\\lib\\vllm\\v1\\engine\n",
      "  copying vllm\\v1\\engine\\__init__.py -> build\\lib\\vllm\\v1\\engine\n",
      "  creating build\\lib\\vllm\\v1\\executor\n",
      "  copying vllm\\v1\\executor\\abstract.py -> build\\lib\\vllm\\v1\\executor\n",
      "  copying vllm\\v1\\executor\\multiproc_executor.py -> build\\lib\\vllm\\v1\\executor\n",
      "  copying vllm\\v1\\executor\\ray_distributed_executor.py -> build\\lib\\vllm\\v1\\executor\n",
      "  copying vllm\\v1\\executor\\__init__.py -> build\\lib\\vllm\\v1\\executor\n",
      "  creating build\\lib\\vllm\\v1\\metrics\n",
      "  copying vllm\\v1\\metrics\\loggers.py -> build\\lib\\vllm\\v1\\metrics\n",
      "  copying vllm\\v1\\metrics\\stats.py -> build\\lib\\vllm\\v1\\metrics\n",
      "  copying vllm\\v1\\metrics\\__init__.py -> build\\lib\\vllm\\v1\\metrics\n",
      "  creating build\\lib\\vllm\\v1\\sample\n",
      "  copying vllm\\v1\\sample\\metadata.py -> build\\lib\\vllm\\v1\\sample\n",
      "  copying vllm\\v1\\sample\\rejection_sampler.py -> build\\lib\\vllm\\v1\\sample\n",
      "  copying vllm\\v1\\sample\\sampler.py -> build\\lib\\vllm\\v1\\sample\n",
      "  copying vllm\\v1\\sample\\__init__.py -> build\\lib\\vllm\\v1\\sample\n",
      "  creating build\\lib\\vllm\\v1\\spec_decode\n",
      "  copying vllm\\v1\\spec_decode\\ngram_proposer.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "  copying vllm\\v1\\spec_decode\\__init__.py -> build\\lib\\vllm\\v1\\spec_decode\n",
      "  creating build\\lib\\vllm\\v1\\stats\n",
      "  copying vllm\\v1\\stats\\common.py -> build\\lib\\vllm\\v1\\stats\n",
      "  copying vllm\\v1\\stats\\__init__.py -> build\\lib\\vllm\\v1\\stats\n",
      "  creating build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\block_table.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\gpu_input_batch.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\gpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\gpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\lora_model_runner_mixin.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\tpu_model_runner.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\tpu_worker.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\worker_base.py -> build\\lib\\vllm\\v1\\worker\n",
      "  copying vllm\\v1\\worker\\__init__.py -> build\\lib\\vllm\\v1\\worker\n",
      "  creating build\\lib\\vllm\\v1\\attention\\backends\n",
      "  copying vllm\\v1\\attention\\backends\\flash_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "  copying vllm\\v1\\attention\\backends\\pallas.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "  copying vllm\\v1\\attention\\backends\\rocm_attn.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "  copying vllm\\v1\\attention\\backends\\__init__.py -> build\\lib\\vllm\\v1\\attention\\backends\n",
      "  creating build\\lib\\vllm\\v1\\sample\\ops\n",
      "  copying vllm\\v1\\sample\\ops\\penalties.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "  copying vllm\\v1\\sample\\ops\\topk_topp_sampler.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "  copying vllm\\v1\\sample\\ops\\__init__.py -> build\\lib\\vllm\\v1\\sample\\ops\n",
      "  running egg_info\n",
      "  writing vllm.egg-info\\PKG-INFO\n",
      "  writing dependency_links to vllm.egg-info\\dependency_links.txt\n",
      "  writing entry points to vllm.egg-info\\entry_points.txt\n",
      "  writing requirements to vllm.egg-info\\requires.txt\n",
      "  writing top-level names to vllm.egg-info\\top_level.txt\n",
      "  ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "  reading manifest file 'vllm.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'vllm.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\FIT\\AppData\\Local\\Temp\\pip-build-env-ml33aw7t\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'vllm.model_executor.layers.fused_moe.configs' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'vllm.model_executor.layers.fused_moe.configs' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'vllm.model_executor.layers.fused_moe.configs' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'vllm.model_executor.layers.fused_moe.configs' to be distributed and are\n",
      "          already explicitly excluding 'vllm.model_executor.layers.fused_moe.configs' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Users\\FIT\\AppData\\Local\\Temp\\pip-build-env-ml33aw7t\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'vllm.model_executor.layers.quantization.utils.configs' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'vllm.model_executor.layers.quantization.utils.configs' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'vllm.model_executor.layers.quantization.utils.configs' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'vllm.model_executor.layers.quantization.utils.configs' to be distributed and are\n",
      "          already explicitly excluding 'vllm.model_executor.layers.quantization.utils.configs' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Users\\FIT\\AppData\\Local\\Temp\\pip-build-env-ml33aw7t\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'vllm.vllm_flash_attn' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'vllm.vllm_flash_attn' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'vllm.vllm_flash_attn' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'vllm.vllm_flash_attn' to be distributed and are\n",
      "          already explicitly excluding 'vllm.vllm_flash_attn' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying vllm\\py.typed -> build\\lib\\vllm\n",
      "  creating build\\lib\\vllm\\vllm_flash_attn\n",
      "  copying vllm\\vllm_flash_attn\\.gitkeep -> build\\lib\\vllm\\vllm_flash_attn\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_L40S.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  creating build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying vllm\\distributed\\kv_transfer\\README.md -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "  copying vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\lib\\vllm\\distributed\\kv_transfer\n",
      "  copying vllm\\model_executor\\layers\\fused_moe\\configs\\README -> build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  installing to build\\bdist.win-amd64\\wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build\\bdist.win-amd64\\wheel\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\request.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\worker_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  copying build\\lib\\vllm\\adapter_commons\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\adapter_commons\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\assets\n",
      "  copying build\\lib\\vllm\\assets\\audio.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "  copying build\\lib\\vllm\\assets\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "  copying build\\lib\\vllm\\assets\\image.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "  copying build\\lib\\vllm\\assets\\video.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "  copying build\\lib\\vllm\\assets\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\assets\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\attention\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\abstract.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\blocksparse_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\flashinfer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\hpu_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\ipex_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\backends\\mla\n",
      "  copying build\\lib\\vllm\\attention\\backends\\mla\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\\mla\n",
      "  copying build\\lib\\vllm\\attention\\backends\\mla\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\\mla\n",
      "  copying build\\lib\\vllm\\attention\\backends\\openvino.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\pallas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\placeholder_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\rocm_flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\torch_sdpa.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\triton_mla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\xformers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\backends\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\backends\n",
      "  copying build\\lib\\vllm\\attention\\layer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\ops\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\blocksparse_attention_kernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\interface.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying build\\lib\\vllm\\attention\\ops\\blocksparse_attention\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\\blocksparse_attention\n",
      "  copying build\\lib\\vllm\\attention\\ops\\hpu_paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\ipex_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\nki_flash_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\paged_attn.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\prefix_prefill.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\triton_decode_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\triton_flash_attention.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\\ops\n",
      "  copying build\\lib\\vllm\\attention\\selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "  copying build\\lib\\vllm\\attention\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\attention\n",
      "  copying build\\lib\\vllm\\beam_search.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\backends.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\compiler_interface.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\counter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\decorators.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\fix_functionalization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\fusion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\fx_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\monitor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\multi_output_match.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\pass_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\reshapes.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\vllm_inductor_pass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\compilation\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\compilation\n",
      "  copying build\\lib\\vllm\\config.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  copying build\\lib\\vllm\\connections.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\core\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\block_table.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\common.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\cpu_gpu_block_allocator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\naive_block.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\prefix_caching_block.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\\block\n",
      "  copying build\\lib\\vllm\\core\\block_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  copying build\\lib\\vllm\\core\\evictor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  copying build\\lib\\vllm\\core\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  copying build\\lib\\vllm\\core\\placeholder_block_space_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  copying build\\lib\\vllm\\core\\scheduler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  copying build\\lib\\vllm\\core\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\core\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\device_allocator\n",
      "  copying build\\lib\\vllm\\device_allocator\\cumem.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
      "  copying build\\lib\\vllm\\device_allocator\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\device_allocator\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\n",
      "  copying build\\lib\\vllm\\distributed\\communication_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\base_device_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\cpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\cuda_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\custom_all_reduce.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\custom_all_reduce_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\hpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\pynccl_wrapper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\shm_broadcast.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\tpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\xpu_communicator.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  copying build\\lib\\vllm\\distributed\\device_communicators\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\device_communicators\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\disagg_prefill_workflow.jpg -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\factory.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\simple_connector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_connector\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_connector\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\simple_buffer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_lookup_buffer\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\mooncake_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\pynccl_pipe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_pipe\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\\kv_pipe\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\kv_transfer_agent.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\README.md -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "  copying build\\lib\\vllm\\distributed\\kv_transfer\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\\kv_transfer\n",
      "  copying build\\lib\\vllm\\distributed\\parallel_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "  copying build\\lib\\vllm\\distributed\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "  copying build\\lib\\vllm\\distributed\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\distributed\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\arg_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\async_llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\async_timeout.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\llm_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\metrics.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\metrics_types.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\engine\\multiprocessing\n",
      "  copying build\\lib\\vllm\\engine\\multiprocessing\\client.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "  copying build\\lib\\vllm\\engine\\multiprocessing\\engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "  copying build\\lib\\vllm\\engine\\multiprocessing\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\multiprocessing\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\interfaces.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\multi_step.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\single_step.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\stop_checker.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\util.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\output_processor\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\\output_processor\n",
      "  copying build\\lib\\vllm\\engine\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  copying build\\lib\\vllm\\engine\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\engine\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\entrypoints\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\entrypoints\\chat_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\cli\\main.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\cli\\openai.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\cli\\serve.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\cli\\types.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\cli\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\cli\n",
      "  copying build\\lib\\vllm\\entrypoints\\launcher.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\entrypoints\\llm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\entrypoints\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\api_server.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\cli_args.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\logits_processors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\protocol.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\\abs_reasoning_parsers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\\deepseek_r1_reasoning_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\reasoning_parsers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\reasoning_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\run_batch.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_chat.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_completion.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_embedding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_engine.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_pooling.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_rerank.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_score.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_tokenization.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\serving_transcription.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\abstract_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_20b_fc_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\granite_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\hermes_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\internlm2_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\jamba_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\llama_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\mistral_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\pythonic_tool_parser.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\tool_parsers\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\\tool_parsers\n",
      "  copying build\\lib\\vllm\\entrypoints\\openai\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\\openai\n",
      "  copying build\\lib\\vllm\\entrypoints\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\entrypoints\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\entrypoints\n",
      "  copying build\\lib\\vllm\\envs.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\executor_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\mp_distributed_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\msgspec_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\multiproc_worker_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\ray_distributed_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\ray_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\uniproc_executor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\executor\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\executor\n",
      "  copying build\\lib\\vllm\\forward_context.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\inputs\\data.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\inputs\\parse.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\inputs\\preprocess.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\inputs\\registry.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\inputs\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\inputs\n",
      "  copying build\\lib\\vllm\\logger.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\logging_utils\n",
      "  copying build\\lib\\vllm\\logging_utils\\formatter.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
      "  copying build\\lib\\vllm\\logging_utils\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\logging_utils\n",
      "  copying build\\lib\\vllm\\logits_process.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\fully_sharded_layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\layers.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\lora.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\models.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\torch_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\torch_ops\\lora_ops.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\torch_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\torch_ops\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\bgmv_expand.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\bgmv_expand_slice.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\bgmv_shrink.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\kernel_utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\sgmv_expand.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\sgmv_shrink.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\triton_ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\\triton_ops\n",
      "  copying build\\lib\\vllm\\lora\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\ops\n",
      "  copying build\\lib\\vllm\\lora\\peft_helper.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_base.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_cpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_gpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_hpu.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\punica_selector.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\punica_wrapper\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\\punica_wrapper\n",
      "  copying build\\lib\\vllm\\lora\\request.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\worker_manager.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  copying build\\lib\\vllm\\lora\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\lora\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\n",
      "  copying build\\lib\\vllm\\model_executor\\custom_op.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\guided_fields.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\lm_format_enforcer_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\outlines_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\outlines_logits_processors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\xgrammar_decoding.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  copying build\\lib\\vllm\\model_executor\\guided_decoding\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\guided_decoding\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\activation.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=3584,device_name=NVIDIA_L40S.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\configs\\README -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_marlin_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\fused_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\layer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_pallas.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\moe_torch_iterative.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\fused_moe\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\fused_moe\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\layernorm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\linear.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\logits_processor.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\mamba\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\mamba_mixer.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\mamba_mixer2.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\causal_conv1d.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\mamba_ssm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_bmm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_scan.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_chunk_state.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_combined.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\ssd_state_passing.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\ops\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\\ops\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\mamba\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\mamba\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\pooler.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\aqlm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\awq_triton.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\base_config.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\bitsandbytes.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\compressed_tensors_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_scheme.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w4a16_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a16_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_w8a8_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\compressed_tensors_wNa16.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\triton_scaled_mm.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\compressed_tensors\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\deepspeedfp.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\experts_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\fbgemm_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gguf.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\gptq_marlin_24.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\hqq_marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\ipex_quant.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\exllama.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\machete.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\MPLinearKernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\mixed_precision\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\cutlass.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\ScaledMMLinearKernel.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\triton.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\xla.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\\scaled_mm\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kernels\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\kernels\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\kv_cache.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\marlin.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\modelopt.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\moe_wna16.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\neuron_quant.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\ptpc_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\qqq.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\quark.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\quark_moe.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_scheme.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_fp8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\quark_w8a8_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\\schemes\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\utils.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\quark\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\quark\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\schema.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\tpu_int8.py -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\utils\n",
      "  creating build\\bdist.win-amd64\\wheel\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  copying build\\lib\\vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\\configs\n",
      "  error: could not create 'build\\bdist.win-amd64\\wheel\\.\\vllm\\model_executor\\layers\\quantization\\utils\\configs\\N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json': No such file or directory\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for vllm\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (vllm)\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct.\n403 Client Error. (Request ID: Root=1-67c665d4-271d878a52c305401eea0cc4;a7d02208-9ea9-4b64-bd1a-3427f95860e9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-3B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:967\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:1482\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1481\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    279\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    280\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    281\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\file_download.py:302\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    301\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 302\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:423\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    420\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    422\u001b[0m     )\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-67c665d4-271d878a52c305401eea0cc4;a7d02208-9ea9-4b64-bd1a-3427f95860e9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-3B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a pirate chatbot who always responds in pirate speak!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     13\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m pipe(\n\u001b[0;32m     16\u001b[0m     messages,\n\u001b[0;32m     17\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\pipelines\\__init__.py:815\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    813\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 815\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    816\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    817\u001b[0m     )\n\u001b[0;32m    818\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    820\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1138\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1135\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1136\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1138\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1139\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1140\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rndAI\\lib\\site-packages\\transformers\\utils\\hub.py:416\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct.\n403 Client Error. (Request ID: Root=1-67c665d4-271d878a52c305401eea0cc4;a7d02208-9ea9-4b64-bd1a-3427f95860e9)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-3B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efc77756fa24eebb1f4aae3c77e387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
